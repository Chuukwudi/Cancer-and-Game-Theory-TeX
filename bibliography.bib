
@article{doi:10.4137/BIC.S33380,
	author = {Harry B. Burke},
	title ={Predicting Clinical Outcomes Using Molecular Biomarkers},
	journal = {Biomarkers in Cancer},
	volume = {8},
	number = {},
	pages = {BIC.S33380},
	year = {2016},
	doi = {10.4137/BIC.S33380},
	note ={PMID: 27279751},
	URL = {https://doi.org/10.4137/BIC.S33380},
	eprint = {https://doi.org/10.4137/BIC.S33380},
	abstract = { Over the past 20 years, there has been an exponential increase in the number of biomarkers. At the last count, there were 768,259 papers indexed in PubMed.gov directly related to biomarkers. Although many of these papers claim to report clinically useful molecular biomarkers, embarrassingly few are currently in clinical use. It is suggested that a failure to properly understand, clinically assess, and utilize molecular biomarkers has prevented their widespread adoption in treatment, in comparative benefit analyses, and their integration into individualized patient outcome predictions for clinical decision-making and therapy. A straightforward, general approach to understanding how to predict clinical outcomes using risk, diagnostic, and prognostic molecular biomarkers is presented. In the future, molecular biomarkers will drive advances in risk, diagnosis, and prognosis, they will be the targets of powerful molecular therapies, and they will individualize and optimize therapy. Furthermore, clinical predictions based on molecular biomarkers will be displayed on the clinician's screen during the physician–patient interaction, they will be an integral part of physician–patient-shared decision-making, and they will improve clinical care and patient outcomes. }
}

@article{10.1093/bib/bby051,
	author = {Lightbody, Gaye and Haberland, Valeriia and Browne, Fiona and Taggart, Laura and Zheng, Huiru and Parkes, Eileen and Blayney, Jaine K},
	title = "{Review of applications of high-throughput sequencing in personalized medicine: barriers and facilitators of future progress in research and clinical application}",
	journal = {Briefings in Bioinformatics},
	volume = {20},
	number = {5},
	pages = {1795-1811},
	year = {2019},
	month = {06},
	abstract = "{There has been an exponential growth in the performance and output of sequencing technologies (omics data) with full genome sequencing now producing gigabases of reads on a daily basis. These data may hold the promise of personalized medicine, leading to routinely available sequencing tests that can guide patient treatment decisions. In the era of high-throughput sequencing (HTS), computational considerations, data governance and clinical translation are the greatest rate-limiting steps. To ensure that the analysis, management and interpretation of such extensive omics data is exploited to its full potential, key factors, including sample sourcing, technology selection and computational expertise and resources, need to be considered, leading to an integrated set of high-performance tools and systems. This article provides an up-to-date overview of the evolution of HTS and the accompanying tools, infrastructure and data management approaches that are emerging in this space, which, if used within in a multidisciplinary context, may ultimately facilitate the development of personalized medicine.}",
	issn = {1477-4054},
	doi = {10.1093/bib/bby051},
	url = {https://doi.org/10.1093/bib/bby051},
	eprint = {https://academic.oup.com/bib/article-pdf/20/5/1795/33616331/bby051.pdf},
}


@Article{Ahmed2007,
	author={Ahmed, Farid E.
	and Vos, Paul W.
	and Holbert, Don},
	title={Modeling survival in colon cancer: a methodological review},
	journal={Molecular Cancer},
	year={2007},
	month={Feb},
	day={12},
	volume={6},
	number={1},
	pages={15},
	abstract={The Cox proportional hazards model is the most widely used model for survival analysis because of its simplicity. The fundamental assumption in this model is the proportionality of the hazard function. When this condition is not met, other modifications or other models must be used for analysis of survival data. We illustrate in this review several methodological approaches to deal with the violation of the proportionality assumption, using survival in colon cancer as an illustrative example.},
	issn={1476-4598},
	doi={10.1186/1476-4598-6-15},
	url={https://doi.org/10.1186/1476-4598-6-15}
}


@Article{Chen2012,
	author={Chen, Hung-Chia
	and Kodell, Ralph L.
	and Cheng, Kuang Fu
	and Chen, James J.},
	title={Assessment of performance of survival prediction models for cancer prognosis},
	journal={BMC Medical Research Methodology},
	year={2012},
	month={Jul},
	day={23},
	volume={12},
	number={1},
	pages={102},
	abstract={Cancer survival studies are commonly analyzed using survival-time prediction models for cancer prognosis. A number of different performance metrics are used to ascertain the concordance between the predicted risk score of each patient and the actual survival time, but these metrics can sometimes conflict. Alternatively, patients are sometimes divided into two classes according to a survival-time threshold, and binary classifiers are applied to predict each patient's class. Although this approach has several drawbacks, it does provide natural performance metrics such as positive and negative predictive values to enable unambiguous assessments.},
	issn={1471-2288},
	doi={10.1186/1471-2288-12-102},
	url={https://doi.org/10.1186/1471-2288-12-102}
}


@Article{Abadi2014,
	author={Abadi, Alireza
	and Yavari, Parvin
	and Dehghani-Arani, Monireh
	and Alavi-Majd, Hamid
	and Ghasemi, Erfan
	and Amanpour, Farzaneh
	and Bajdik, Chris},
	title={Cox models survival analysis based on breast cancer treatments},
	journal={Iranian journal of cancer prevention},
	year={2014},
	publisher={Cancer Research Center, Shahid Beheshti University of Medical Sciences},
	volume={7},
	number={3},
	pages={124-129},
	keywords={Breast cancer; Cox PH regression; Stratified Cox model; Treatment},
	abstract={BACKGROUND: The aim of this study is to evaluate the association between different treatments and survival time of breast cancer patients using either standard Cox model or stratified Cox model. METHODS: The study was conducted on 15830 women diagnosed with breast cancer in British Columbia, Canada. They were divided into eight groups according to patients' ages and stage of disease Either Cox's PH model or stratified Cox model was fitted to each group according to the PH assumption and tested using Schoenfeld residuals. RESULTS: The data show that in the group of patients under age 50 years old and over age 50 with stage I cancer, the highest hazard was related to radiotherapy (HR= 3.15, CI: 1.85-5.35) and chemotherapy (HR= 3, CI: 2.29- 3.93) respectively. For both groups of patients with stage II cancer, the highest risk was related to radiotherapy (HR=3.02, CI: 2.26-4.03) (HR=2.16, CI:1.85-2.52). For both groups of patients with stage III cancer, the highest risk was for surgery (HR=0.49, CI: 0.33-0.73), (HR=0.45, CI: 0.36-0.57). For patients of age 50 years or less with stage IV cancer, none of the treatments were statistically significant. In group of patients over age 50 years old with stage IV cancer, the highest hazard was related to surgery (HR=0.64, CI: 0.53-0.78). CONCLUSION: The results of this study show that for patients with stage I and II breast cancer, radiotherapy and chemotherapy had the highest hazard; for patients with stage III and IV breast cancer, the highest hazard was associated with treatment surgery.},
	note={25250162[pmid]},
	note={PMC4171826[pmcid]},
	issn={2008-2398},
	url={https://pubmed.ncbi.nlm.nih.gov/25250162},
	language={eng}
}


@ARTICLE{Atashgar, 
	author = {Atashgar, Karim and Sheikhaliyan, Ayeh and Tajvidi, Mina and Molana, Seyed Hadi and Jalaeiyan, Leyla and },  
	title = {Survival analysis of breast cancer patients with different chronic diseases through parametric and semi-parametric approaches}, 
	volume = {2}, 
	number = {1},  
	abstract ={Introduction: There is a lack of information on the extent of dependency between chronic diseases and the survival rate of breast cancer. Until date, none of the models proposed has determined the impact of chronic diseases on breast cancer survival. This study, therefore, aimed to investigate the impacts of chronic diseases such as diabetes, blood pressure, and endocrine disorders on the survival of breast cancer patients through a comprehensive research.  Methods: All (n = 1822) breast cancer patients treated in the three hospitals of Tehran from 2007 through mid&ndash;2016 were included in this study. A comprehensive study was conducted by focusing on the chronic disease data of the studied patients. The parametric and semi-parametric approaches, as well as non-parametric Kaplan-Meier analysis, were performed. This research proposes two models for analyzing breast cancer survival. A comparative analysis of the models was performed based on the Akaike criterion.  Results: Chronic diseases have been found to affect the survival of breast cancer patients. This research considered 436 individuals, among the patients with chronic diseases including hypertension, diabetes, hypo- and hyperthyroidism, and heart problems at the frequencies of 12.38%, 11.69%, 8.71%, and 8.02%, respectively. This study indicated that the 5-year survival of breast cancer patients with chronic diseases was 72% and that it was 82% for other breast cancer patients. The statistical analysis and the two proposed models revealed that chronic diseases significantly affect the survival of the   study patients.  Conclusions: This comprehensive research evidence a significant difference in the survival rate of breast cancer patients with and without chronic diseases. The statistical analysis of the data indicated that chronic diseases can significantly affect the survival probability in breast cancer. Heart problems and the combination of chronic diseases have a major influence on the survival rate of breast cancer patients as compared to other cases. },  
	URL = {http://mcijournal.com/article-1-69-en.html},  
	eprint = {http://mcijournal.com/article-1-69-en.pdf},  
	journal = {Multidisciplinary Cancer Investigation},   
	doi = {10.30699/acadpub.mci.2.1.26},  
	year = {2018}  
}


@article{Witten2009,
	doi = {10.1177/0962280209105024},
	url = {https://doi.org/10.1177/0962280209105024},
	year = {2009},
	month = aug,
	publisher = {{SAGE} Publications},
	volume = {19},
	number = {1},
	pages = {29--51},
	author = {Daniela M Witten and Robert Tibshirani},
	title = {Survival analysis with high-dimensional covariates},
	journal = {Statistical Methods in Medical Research}
}


@article{10.1093/biomet/asm037,
	author = {Zhang, Hao Helen and Lu, Wenbin},
	title = "{Adaptive Lasso for Cox's proportional hazards model}",
	journal = {Biometrika},
	volume = {94},
	number = {3},
	pages = {691-703},
	year = {2007},
	month = {05},
	abstract = "{We investigate the variable selection problem for Cox's proportional hazards model, and propose a unified model selection and estimation procedure with desired theoretical properties and computational convenience. The new method is based on a penalized log partial likelihood with the adaptively weighted L1 penalty on regression coefficients, providing what we call the adaptive Lasso estimator. The method incorporates different penalties for different coefficients: unimportant variables receive larger penalties than important ones, so that important variables tend to be retained in the selection process, whereas unimportant variables are more likely to be dropped. Theoretical properties, such as consistency and rate of convergence of the estimator, are studied. We also show that, with proper choice of regularization parameters, the proposed estimator has the oracle properties. The convex optimization nature of the method leads to an efficient algorithm. Both simulated and real examples show that the method performs competitively.}",
	issn = {0006-3444},
	doi = {10.1093/biomet/asm037},
	url = {https://doi.org/10.1093/biomet/asm037},
	eprint = {https://academic.oup.com/biomet/article-pdf/94/3/691/731653/asm037.pdf},
}


@article{Tibshirani+2009,
	author = {Robert J. Tibshirani},
	doi = {doi:10.2202/1544-6115.1438},
	url = {https://doi.org/10.2202/1544-6115.1438},
	title = {Univariate Shrinkage in the Cox Model for High Dimensional Data: },
	journal = {Statistical Applications in Genetics and Molecular Biology},
	number = {1},
	volume = {8},
	year = {2009}
}

@article{JSSv039i05,
	author = {Noah Simon and Jerome H. Friedman and Trevor Hastie and Rob Tibshirani},
	title = {Regularization Paths for Cox's Proportional Hazards Model via Coordinate Descent},
	journal = {Journal of Statistical Software, Articles},
	volume = {39},
	number = {5},
	year = {2011},
	keywords = {},
	abstract = {We introduce a pathwise algorithm for the Cox proportional hazards model, regularized by convex combinations of l1 and l2 penalties (elastic net). Our algorithm fits via cyclical coordinate descent, and employs warm starts to find a solution along a regularization path. We demonstrate the efficacy of our algorithm on real and simulated data sets, and find considerable speedup between our algorithm and competing methods.},
	issn = {1548-7660},
	pages = {1--13},
	doi = {10.18637/jss.v039.i05},
	url = {https://www.jstatsoft.org/v039/i05}
}


@Article{Xu2012,
	author={Xu, Jinfeng},
	title={High-Dimensional Cox Regression Analysis in Genetic Studies with Censored Survival Outcomes},
	journal={Journal of Probability and Statistics},
	year={2012},
	month={Jul},
	day={15},
	publisher={Hindawi Publishing Corporation},
	volume={2012},
	pages={478680},
	abstract={With the advancement of high-throughput technologies, nowadays high-dimensional genomic and proteomic data are easy to obtain and have become ever increasingly important in unveiling the complex etiology of many diseases. While relating a large number of  factors to a survival outcome through the Cox relative risk model, various techniques have been proposed in the literature. We review some recently developed methods for such analysis. For high-dimensional variable selection in the Cox model with parametric relative risk, we consider the univariate shrinkage method (US) using the lasso penalty and the penalized partial likelihood method using the folded penalties (PPL). The penalization methods are not restricted to the finite-dimensional case. For the high-dimensional (<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M1"><mml:mrow><mml:mi>p</mml:mi><mml:mo>{\&}{\#}x2192;</mml:mo><mml:mi>{\&}{\#}x221e;</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M2"><mml:mi>p</mml:mi><mml:mo>{\&}{\#}x226a;</mml:mo><mml:mi>n</mml:mi></mml:math></inline-formula>) or ultrahigh-dimensional case (<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M3"><mml:mrow><mml:mi>n</mml:mi><mml:mo>{\&}{\#}x2192;</mml:mo><mml:mi>{\&}{\#}x221e;</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M4"><mml:mi>n</mml:mi><mml:mo>{\&}{\#}x226a;</mml:mo><mml:mi>p</mml:mi></mml:math></inline-formula>), both the sure independence screening (SIS) method and the extended Bayesian information criterion (EBIC) can be further incorporated into the penalization methods for variable selection. We also consider the penalization method for the Cox model with semiparametric relative risk, and the modified partial least squares method for the Cox model. The comparison of different methods is discussed and numerical examples are provided for the illustration. Finally, areas of further research are presented.},
	issn={1687-952X},
	doi={10.1155/2012/478680},
	url={https://doi.org/10.1155/2012/478680}
}


@incollection{Fan2010,
	doi = {10.1214/10-imscoll606},
	url = {https://doi.org/10.1214/10-imscoll606},
	year = {2010},
	publisher = {Institute of Mathematical Statistics},
	pages = {70--86},
	author = {Jianqing Fan and Yang Feng and Yichao Wu},
	title = {High-dimensional variable selection for Cox's proportional hazards model},
	booktitle = {Institute of Mathematical Statistics Collections}
}

@article{MALLAVARAPU202024,
	title = {Pathway-based deep clustering for molecular subtyping of cancer},
	journal = {Methods},
	volume = {173},
	pages = {24-31},
	year = {2020},
	note = {Multiscale Network-based Approaches},
	issn = {1046-2023},
	doi = {https://doi.org/10.1016/j.ymeth.2019.06.017},
	url = {https://www.sciencedirect.com/science/article/pii/S1046202319300489},
	author = {Tejaswini Mallavarapu and Jie Hao and Youngsoon Kim and Jung Hun Oh and Mingon Kang},
	keywords = {Cancer subtyping, Clustering, Pathway-based analysis, Ovarian cancer, TCGA},
	abstract = {Cancer is a genetic disease comprising multiple subtypes that have distinct molecular characteristics and clinical features. Cancer subtyping helps in improving personalized treatment and making decision, as different cancer subtypes respond differently to the treatment. The increasing availability of cancer related genomic data provides the opportunity to identify molecular subtypes. Several unsupervised machine learning techniques have been applied on molecular data of the tumor samples to identify cancer subtypes that are genetically and clinically distinct. However, most clustering methods often fail to efficiently cluster patients due to the challenges imposed by high-throughput genomic data and its non-linearity. In this paper, we propose a pathway-based deep clustering method (PACL) for molecular subtyping of cancer, which incorporates gene expression and biological pathway database to group patients into cancer subtypes. The main contribution of our model is to discover high-level representations of biological data by learning complex hierarchical and nonlinear effects of pathways. We compared the performance of our model with a number of benchmark clustering methods that recently have been proposed in cancer subtypes. We assessed the hypothesis that clusters (subtypes) may be associated to different survivals by logrank tests. PACL showed the lowest p-value of the logrank test against the benchmark methods. It demonstrates the patient groups clustered by PACL may correspond to subtypes which are significantly associated with distinct survival distributions. Moreover, PACL provides a solution to comprehensively identify subtypes and interpret the model in the biological pathway level. The open-source software of PACL in PyTorch is publicly available at https://github.com/tmallava/PACL.}
}

@inproceedings{LI2002,
	doi = {10.1142/9789812776303_0007},
	url = {https://doi.org/10.1142/9789812776303_0007},
	year = {2002},
	month = dec,
	publisher = {{WORLD} {SCIENTIFIC}},
	author = {HONGZHE LI and YIHUI LUAN},
	title = {{KERNEL} {COX} {REGRESSION} {MODELS} {FOR} {LINKING} {GENE} {EXPRESSION} {PROFILES} {TO} {CENSORED} {SURVIVAL} {DATA}},
	booktitle = {Biocomputing 2003}
}


@article{10.1093/bioinformatics/btn253,
	author = {Evers, Ludger and Messow, Claudia-Martina},
	title = "{Sparse kernel methods for high-dimensional survival data}",
	journal = {Bioinformatics},
	volume = {24},
	number = {14},
	pages = {1632-1638},
	year = {2008},
	month = {05},
	abstract = "{Sparse kernel methods like support vector machines (SVM) have been applied with great success to classification and (standard) regression settings. Existing support vector classification and regression techniques however are not suitable for partly censored survival data, which are typically analysed using Cox's proportional hazards model. As the partial likelihood of the proportional hazards model only depends on the covariates through inner products, it can be ‘kernelized’. The kernelized proportional hazards model however yields a solution that is dense, i.e. the solution depends on all observations. One of the key features of an SVM is that it yields a sparse solution, depending only on a small fraction of the training data. We propose two methods. One is based on a geometric idea, where—akin to support vector classification—the margin between the failed observation and the observations currently at risk is maximised. The other approach is based on obtaining a sparse model by adding observations one after another akin to the Import Vector Machine (IVM). Data examples studied suggest that both methods can outperform competing approaches.Availability: Software is available under the GNU Public License as an R package and can be obtained from the first author's website http://www.maths.bris.ac.uk/~maxle/software.htmlContact:l.evers@bris.ac.uk}",
	issn = {1367-4803},
	doi = {10.1093/bioinformatics/btn253},
	url = {https://doi.org/10.1093/bioinformatics/btn253},
	eprint = {https://academic.oup.com/bioinformatics/article-pdf/24/14/1632/443388/btn253.pdf},
}


@Article{Katzman2018,
	author={Katzman, Jared L.
	and Shaham, Uri
	and Cloninger, Alexander
	and Bates, Jonathan
	and Jiang, Tingting
	and Kluger, Yuval},
	title={DeepSurv: personalized treatment recommender system using a Cox proportional hazards deep neural network},
	journal={BMC Medical Research Methodology},
	year={2018},
	month={Feb},
	day={26},
	volume={18},
	number={1},
	pages={24},
	abstract={Medical practitioners use survival models to explore and understand the relationships between patients' covariates (e.g. clinical and genetic features) and the effectiveness of various treatment options. Standard survival models like the linear Cox proportional hazards model require extensive feature engineering or prior medical knowledge to model treatment interaction at an individual level. While nonlinear survival methods, such as neural networks and survival forests, can inherently model these high-level interaction terms, they have yet to be shown as effective treatment recommender systems.},
	issn={1471-2288},
	doi={10.1186/s12874-018-0482-1},
	url={https://doi.org/10.1186/s12874-018-0482-1}
}

@article{Ching2018,
	doi = {10.1371/journal.pcbi.1006076},
	url = {https://doi.org/10.1371/journal.pcbi.1006076},
	year = {2018},
	month = apr,
	publisher = {Public Library of Science ({PLoS})},
	volume = {14},
	number = {4},
	pages = {e1006076},
	author = {Travers Ching and Xun Zhu and Lana X. Garmire},
	editor = {Florian Markowetz},
	title = {Cox-nnet: An artificial neural network method for prognosis prediction of high-throughput omics data},
	journal = {{PLOS} Computational Biology}
}

@Article{Yousefi2017,
	author={Yousefi, Safoora
	and Amrollahi, Fatemeh
	and Amgad, Mohamed
	and Dong, Chengliang
	and Lewis, Joshua E.
	and Song, Congzheng
	and Gutman, David A.
	and Halani, Sameer H.
	and Velazquez Vega, Jose Enrique
	and Brat, Daniel J.
	and Cooper, Lee A. D.},
	title={Predicting clinical outcomes from large scale cancer genomic profiles with deep survival models},
	journal={Scientific Reports},
	year={2017},
	month={Sep},
	day={15},
	volume={7},
	number={1},
	pages={11707},
	abstract={Translating the vast data generated by genomic platforms into accurate predictions of clinical outcomes is a fundamental challenge in genomic medicine. Many prediction methods face limitations in learning from the high-dimensional profiles generated by these platforms, and rely on experts to hand-select a small number of features for training prediction models. In this paper, we demonstrate how deep learning and Bayesian optimization methods that have been remarkably successful in general high-dimensional prediction tasks can be adapted to the problem of predicting cancer outcomes. We perform an extensive comparison of Bayesian optimized deep survival models and other state of the art machine learning methods for survival analysis, and describe a framework for interpreting deep survival models using a risk backpropagation technique. Finally, we illustrate that deep survival models can successfully transfer information across diseases to improve prognostic accuracy. We provide an open-source software implementation of this framework called SurvivalNet that enables automatic training, evaluation and interpretation of deep survival models.},
	issn={2045-2322},
	doi={10.1038/s41598-017-11817-6},
	url={https://doi.org/10.1038/s41598-017-11817-6}
}

@Article{W2019,
	author={W{\'o}jcik, Piotr Iwo
	and Kurdziel, Marcin},
	title={Training neural networks on high-dimensional data using random projection},
	journal={Pattern Analysis and Applications},
	year={2019},
	month={Aug},
	day={01},
	volume={22},
	number={3},
	pages={1221-1231},
	abstract={Training deep neural networks (DNNs) on high-dimensional data with no spatial structure poses a major computational problem. It implies a network architecture with a huge input layer, which greatly increases the number of weights, often making the training infeasible. One solution to this problem is to reduce the dimensionality of the input space to a manageable size, and then train a deep network on a representation with fewer dimensions. Here, we focus on performing the dimensionality reduction step by randomly projecting the input data into a lower-dimensional space. Conceptually, this is equivalent to adding a random projection (RP) layer in front of the network. We study two variants of RP layers: one where the weights are fixed, and one where they are fine-tuned during network training. We evaluate the performance of DNNs with input layers constructed using several recently proposed RP schemes. These include: Gaussian, Achlioptas', Li's, subsampled randomized Hadamard transform (SRHT) and Count Sketch-based constructions. Our results demonstrate that DNNs with RP layer achieve competitive performance on high-dimensional real-world datasets. In particular, we show that SRHT and Count Sketch-based projections provide the best balance between the projection time and the network performance.},
	issn={1433-755X},
	doi={10.1007/s10044-018-0697-0},
	url={https://doi.org/10.1007/s10044-018-0697-0}
}


@article{doi:10.1089/cmb.2015.0189,
	author = {Li, Yifeng and Chen, Chih-Yu and Wasserman, Wyeth W.},
	title = {Deep Feature Selection: Theory and Application to Identify Enhancers and Promoters},
	journal = {Journal of Computational Biology},
	volume = {23},
	number = {5},
	pages = {322-336},
	year = {2016},
	doi = {10.1089/cmb.2015.0189},
	note ={PMID: 26799292},
	
	URL = { 
	https://doi.org/10.1089/cmb.2015.0189
	
	},
	eprint = { 
	https://doi.org/10.1089/cmb.2015.0189
	
	}
	,
	abstract = { Abstract Sparse linear models approximate target variable(s) by a sparse linear combination of input variables. Since they are simple, fast, and able to select features, they are widely used in classification and regression. Essentially they are shallow feed-forward neural networks that have three limitations: (1) incompatibility to model nonlinearity of features, (2) inability to learn high-level features, and (3) unnatural extensions to select features in a multiclass case. Deep neural networks are models structured by multiple hidden layers with nonlinear activation functions. Compared with linear models, they have two distinctive strengths: the capability to (1) model complex systems with nonlinear structures and (2) learn high-level representation of features. Deep learning has been applied in many large and complex systems where deep models significantly outperform shallow ones. However, feature selection at the input level, which is very helpful to understand the nature of a complex system, is still not well studied. In genome research, the cis-regulatory elements in noncoding DNA sequences play a key role in the expression of genes. Since the activity of regulatory elements involves highly interactive factors, a deep tool is strongly needed to discover informative features. In order to address the above limitations of shallow and deep models for selecting features of a complex system, we propose a deep feature selection (DFS) model that (1) takes advantages of deep structures to model nonlinearity and (2) conveniently selects a subset of features right at the input level for multiclass data. Simulation experiments convince us that this model is able to correctly identify both linear and nonlinear features. We applied this model to the identification of active enhancers and promoters by integrating multiple sources of genomic information. Results show that our model outperforms elastic net in terms of size of discriminative feature subset and classification accuracy. }
}

@inproceedings{ijcai2017-318,
	author    = {Bo Liu and Ying Wei and Yu Zhang and Qiang Yang},
	title     = {Deep Neural Networks for High Dimension, Low Sample Size Data},
	booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on
	Artificial Intelligence, {IJCAI-17}},
	pages     = {2287--2293},
	year      = {2017},
	doi       = {10.24963/ijcai.2017/318},
	url       = {https://doi.org/10.24963/ijcai.2017/318},
}

@Article{Huang2016,
	author={Huang, Sijia
	and Chong, Nicole
	and Lewis, Nathan E.
	and Jia, Wei
	and Xie, Guoxiang
	and Garmire, Lana X.},
	title={Novel personalized pathway-based metabolomics models reveal key metabolic pathways for breast cancer diagnosis},
	journal={Genome Medicine},
	year={2016},
	month={Mar},
	day={31},
	volume={8},
	number={1},
	pages={34},
	abstract={More accurate diagnostic methods are pressingly needed to diagnose breast cancer, the most common malignant cancer in women worldwide. Blood-based metabolomics is a promising diagnostic method for breast cancer. However, many metabolic biomarkers are difficult to replicate among studies.},
	issn={1756-994X},
	doi={10.1186/s13073-016-0289-9},
	url={https://doi.org/10.1186/s13073-016-0289-9}
}

@article{Masson2014,
	doi = {10.1371/journal.pone.0108075},
	url = {https://doi.org/10.1371/journal.pone.0108075},
	year = {2014},
	month = sep,
	publisher = {Public Library of Science ({PLoS})},
	volume = {9},
	number = {9},
	pages = {e108075},
	author = {Patrick Masson and Chantal Hulo and Edouard de Castro and Rebecca Foulger and Sylvain Poux and Alan Bridge and Jane Lomax and Lydie Bougueleret and Ioannis Xenarios and Philippe Le Mercier},
	editor = {Michelle L. Baker},
	title = {An Integrated Ontology Resource to Explore and Study Host-Virus Relationships},
	journal = {{PLoS} {ONE}}
}

@article{10.1371/journal.pone.0154313,
	doi = {10.1371/journal.pone.0154313},
	author = {Lu, Jie AND Cowperthwaite, Matthew C. AND Burnett, Mark G. AND Shpak, Max},
	journal = {PLOS ONE},
	publisher = {Public Library of Science},
	title = {Molecular Predictors of Long-Term Survival in Glioblastoma Multiforme Patients},
	year = {2016},
	month = {04},
	volume = {11},
	url = {https://doi.org/10.1371/journal.pone.0154313},
	pages = {1-22},
	abstract = {Glioblastoma multiforme (GBM) is the most common and aggressive adult primary brain cancer, with <10% of patients surviving for more than 3 years. Demographic and clinical factors (e.g. age) and individual molecular biomarkers have been associated with prolonged survival in GBM patients. However, comprehensive systems-level analyses of molecular profiles associated with long-term survival (LTS) in GBM patients are still lacking. We present an integrative study of molecular data and clinical variables in these long-term survivors (LTSs, patients surviving >3 years) to identify biomarkers associated with prolonged survival, and to assess the possible similarity of molecular characteristics between LGG and LTS GBM. We analyzed the relationship between multivariable molecular data and LTS in GBM patients from the Cancer Genome Atlas (TCGA), including germline and somatic point mutation, gene expression, DNA methylation, copy number variation (CNV) and microRNA (miRNA) expression using logistic regression models. The molecular relationship between GBM LTS and LGG tumors was examined through cluster analysis. We identified 13, 94, 43, 29, and 1 significant predictors of LTS using Lasso logistic regression from the somatic point mutation, gene expression, DNA methylation, CNV, and miRNA expression data sets, respectively. Individually, DNA methylation provided the best prediction performance (AUC = 0.84). Combining multiple classes of molecular data into joint regression models did not improve prediction accuracy, but did identify additional genes that were not significantly predictive in individual models. PCA and clustering analyses showed that GBM LTS typically had gene expression profiles similar to non-LTS GBM. Furthermore, cluster analysis did not identify a close affinity between LTS GBM and LGG, nor did we find a significant association between LTS and secondary GBM. The absence of unique LTS profiles and the lack of similarity between LTS GBM and LGG, indicates that there are multiple genetic and epigenetic pathways to LTS in GBM patients.},
	number = {4},
	
}

@Article{Zhu2017,
	author={Zhu, Bin
	and Song, Nan
	and Shen, Ronglai
	and Arora, Arshi
	and Machiela, Mitchell J.
	and Song, Lei
	and Landi, Maria Teresa
	and Ghosh, Debashis
	and Chatterjee, Nilanjan
	and Baladandayuthapani, Veera
	and Zhao, Hongyu},
	title={Integrating Clinical and Multiple Omics Data for Prognostic Assessment across Human Cancers},
	journal={Scientific Reports},
	year={2017},
	month={Dec},
	day={05},
	volume={7},
	number={1},
	pages={16954},
	abstract={Multiple omic profiles have been generated for many cancer types; however, comprehensive assessment of their prognostic values across cancers is limited. We conducted a pan-cancer prognostic assessment and presented a multi-omic kernel machine learning method to systematically quantify the prognostic values of high-throughput genomic, epigenomic, and transcriptomic profiles individually, integratively, and in combination with clinical factors for 3,382 samples across 14 cancer types. We found that the prognostic performance varied substantially across cancer types. mRNA and miRNA expression profile frequently performed the best, followed by DNA methylation profile. Germline susceptibility variants displayed low prognostic performance consistently across cancer types. The integration of omic profiles with clinical variables can lead to substantially improved prognostic performance over the use of clinical variables alone in half of cancer types examined. Moreover, we showed that the kernel machine learning method consistently outperformed existing prognostic signatures, suggesting that including a large number of omic biomarkers may provide substantial improvement in prognostic assessment. Our study provides a comprehensive portrait of omic architecture for tumor prognosis across cancers, and highlights the prognostic value of genome-wide omic biomarker aggregation, which may facilitate refined prognostic assessment in the era of precision oncology.},
	issn={2045-2322},
	doi={10.1038/s41598-017-17031-8},
	url={https://doi.org/10.1038/s41598-017-17031-8}
}

@article{Zhang2013,
	doi = {10.1016/j.celrep.2013.07.010},
	url = {https://doi.org/10.1016/j.celrep.2013.07.010},
	year = {2013},
	month = aug,
	publisher = {Elsevier {BV}},
	volume = {4},
	number = {3},
	pages = {542--553},
	author = {Wei Zhang and Yi Liu and Na Sun and Dan Wang and Jerome Boyd-Kirkup and Xiaoyang Dou and Jing-Dong~Jackie Han},
	title = {Integrating Genomic,  Epigenomic,  and Transcriptomic Features Reveals Modular Signatures Underlying Poor Prognosis in Ovarian Cancer},
	journal = {Cell Reports}
}


@INPROCEEDINGS{8621345,
	 author={Hao, Jie and Kim, Youngsoon and Mallavarapu, Tejaswini and Oh, Jung Hun and Kang, Mingon},  booktitle={2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},   title={Cox-PASNet: Pathway-based Sparse Deep Neural Network for Survival Analysis},  
	 year={2018},  
	 volume={},  
	 number={},  
	 pages={381-386},  
	 doi={10.1109/BIBM.2018.8621345}}



@article {no28,
	author = {Hanif, Farina and Muzaffar, Kanza and Perveen, kahkashan and Malhi, Saima and Simjee, Shabana},
	title = {Glioblastoma Multiforme: A Review of its Epidemiology and Pathogenesis through Clinical Presentation and Treatment},
	journal = {Asian Pacific Journal of Cancer Prevention},
	volume = {18},
	number = {1},
	pages = {3-9},
	year  = {2017},
	publisher = {West Asia Organization for Cancer Prevention (WAOCP), APOCP's West Asia Chapter},
	issn = {1513-7368}, 
	eissn = {2476-762X}, 
	doi = {10.22034/APJCP.2017.18.1.3},
	abstract = {  Glioblastoma multiforme (GBM) is one of the most malignant types of central nervous system tumors. Despite advances in treatment modalities it remains largely incurable. The objective of our review is to provide a holistic picture of GBM epidemiology, etiology, pathogenesis, clinical findings and treatment. A literature search was conducted for GBM at PubMed and Google Scholar, with relevant key words like glioblastoma multiforme, pathogenesis, signs and symptoms, treatment etc., and papers published until 2015 were reviewed. It was found that radiation and certain genetic syndromes are the only risk factors identified to date for GBM. Depending on the tumor site patients may present to the clinic with varying symptoms. To confirm the presence and the extent of tumor, various invasive and non-invasive imaging techniques require employment. The literature survey revealed the pathogenesis to involve aberrations of multiple signaling pathways through multiple genetic mutations and altered gene expression. Although several treatment options are available, including surgery, along with adjuvant chemo- and radio-therapy, the disease has a poor prognosis and patients generally succumb within 14 months of diagnosis.},
	keywords = {Glioblastoma Multiforme,Epidemiology,MRI scan,mutations,Temozolomide},	
	url = {http://journal.waocp.org/article_42593.html},
	eprint = {http://journal.waocp.org/article_42593_ac801aaa3721f49b0f79bc0c790bfac0.pdf}
}


@article{BrettM2017,
	doi = {10.20892/j.issn.2095-3941.2016.0084},
	url = {https://doi.org/10.20892/j.issn.2095-3941.2016.0084},
	year = {2017},
	publisher = {Cancer Biology and Medicine},
	volume = {14},
	number = {1},
	pages = {9--32},
	author = {Reid Brett and Permuth Jennifer and Sellers Thomas},
	title = {Epidemiology of ovarian cancer: a review},
	journal = {Cancer Biology {\&} Medicine}
}


@article {Subramanian15545,
	author = {Subramanian, Aravind and Tamayo, Pablo and Mootha, Vamsi K. and Mukherjee, Sayan and Ebert, Benjamin L. and Gillette, Michael A. and Paulovich, Amanda and Pomeroy, Scott L. and Golub, Todd R. and Lander, Eric S. and Mesirov, Jill P.},
	title = {Gene set enrichment analysis: A knowledge-based approach for interpreting genome-wide expression profiles},
	volume = {102},
	number = {43},
	pages = {15545--15550},
	year = {2005},
	doi = {10.1073/pnas.0506580102},
	publisher = {National Academy of Sciences},
	abstract = {Although genomewide RNA expression analysis has become a routine tool in biomedical research, extracting biological insight from such information remains a major challenge. Here, we describe a powerful analytical method called Gene Set Enrichment Analysis (GSEA) for interpreting gene expression data. The method derives its power by focusing on gene sets, that is, groups of genes that share common biological function, chromosomal location, or regulation. We demonstrate how GSEA yields insights into several cancer-related data sets, including leukemia and lung cancer. Notably, where single-gene analysis finds little similarity between two independent studies of patient survival in lung cancer, GSEA reveals many biological pathways in common. The GSEA method is embodied in a freely available software package, together with an initial database of 1,325 biologically defined gene sets.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/102/43/15545},
	eprint = {https://www.pnas.org/content/102/43/15545.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}


@Article{Reimand2019,
	author={Reimand, J{\"u}ri
	and Isserlin, Ruth
	and Voisin, Veronique
	and Kucera, Mike
	and Tannus-Lopes, Christian
	and Rostamianfar, Asha
	and Wadi, Lina
	and Meyer, Mona
	and Wong, Jeff
	and Xu, Changjiang
	and Merico, Daniele
	and Bader, Gary D.},
	title={Pathway enrichment analysis and visualization of omics data using g:Profiler, GSEA, Cytoscape and EnrichmentMap},
	journal={Nature Protocols},
	year={2019},
	month={Feb},
	day={01},
	volume={14},
	number={2},
	pages={482-517},
	abstract={Pathway enrichment analysis helps researchers gain mechanistic insight into gene lists generated from genome-scale (omics) experiments. This method identifies biological pathways that are enriched in a gene list more than would be expected by chance. We explain the procedures of pathway enrichment analysis and present a practical step-by-step guide to help interpret gene lists resulting from RNA-seq and genome-sequencing experiments. The protocol comprises three major steps: definition of a gene list from omics data, determination of statistically enriched pathways, and visualization and interpretation of the results. We describe how to use this protocol with published examples of differentially expressed genes and mutated cancer genes; however, the principles can be applied to diverse types of omics data. The protocol describes innovative visualization techniques, provides comprehensive background and troubleshooting guidelines, and uses freely available and frequently updated software, including g:Profiler, Gene Set Enrichment Analysis (GSEA), Cytoscape and EnrichmentMap. The complete protocol can be performed in {\textasciitilde}4.5 h and is designed for use by biologists with no prior bioinformatics training.},
	issn={1750-2799},
	doi={10.1038/s41596-018-0103-9},
	url={https://doi.org/10.1038/s41596-018-0103-9}
}


@misc{kingma2017adam,
	title={Adam: A Method for Stochastic Optimization}, 
	author={Diederik P. Kingma and Jimmy Ba},
	year={2017},
	eprint={1412.6980},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}


@article{DBLP:journals/corr/Martinez-Cantin14,
	author    = {Ruben Martinez{-}Cantin},
	title     = {BayesOpt: {A} Bayesian Optimization Library for Nonlinear Optimization,
	Experimental Design and Bandits},
	journal   = {CoRR},
	volume    = {abs/1405.7430},
	year      = {2014},
	url       = {http://arxiv.org/abs/1405.7430},
	archivePrefix = {arXiv},
	eprint    = {1405.7430},
	timestamp = {Mon, 13 Aug 2018 16:46:18 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/Martinez-Cantin14.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}






















































































































































































































@Article{Hao2019,
	author={Hao, Jie and Kim, Youngsoon and Mallavarapu, Tejaswini and Oh, Jung Hun and Kang, Mingon},
	title={Interpretable deep neural network for cancer survival analysis by integrating genomic and clinical data},
	journal={BMC Medical Genomics},
	year={2019},
	month={Dec},
	day={23},
	volume={12},
	number={10},
	pages={189},
	abstract={Understanding the complex biological mechanisms of cancer patient survival using genomic and clinical data is vital, not only to develop new treatments for patients, but also to improve survival prediction. However, highly nonlinear and high-dimension, low-sample size (HDLSS) data cause computational challenges to applying conventional survival analysis.},
	issn={1755-8794},
	doi={10.1186/s12920-019-0624-2},
	url={https://doi.org/10.1186/s12920-019-0624-2}
}

@Article{googledoc,
	author={Google\_AutoML\_Documentation},
	title={Best Practices for Creating Training data, AutoML tables\_2021},
	journal={Google Cloud},
	year={2021},
	url={https://cloud.google.com/automl-tables/docs/data-best-practices}
}

